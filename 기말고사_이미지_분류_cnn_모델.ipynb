{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Load train.xlsx and val.xlsx\n",
        "train_df = pd.read_excel('/content/train2.xlsx')\n",
        "val_df = pd.read_excel('/content/val2.xlsx')\n",
        "\n",
        "# 경로 수정\n",
        "train_df['names'] = train_df['names'].str.replace('\\\\', '/')\n",
        "\n",
        "train_images = train_df['names'].tolist()\n",
        "train_labels = train_df['labels'].tolist()\n",
        "\n",
        "val_images = val_df['names'].tolist()\n",
        "val_labels = val_df['labels'].tolist()\n",
        "\n",
        "# class_reduce = 0.1  # 부류 수 줄여서 데이터양 줄임(속도와 메모리 효율을 위해)\n",
        "no_class = len(train_df['labels'].unique())  # 부류 개수\n",
        "x_train, y_train = [], []\n",
        "\n",
        "for image_path, label in zip(train_images, train_labels):\n",
        "    img = image.load_img(image_path, target_size=(32, 32))\n",
        "    if len(img.getbands()) != 3:\n",
        "        print(\"주의: 유효하지 않은 영상 발생\", image_path)\n",
        "        continue\n",
        "    x = image.img_to_array(img)\n",
        "    x = preprocess_input(x)\n",
        "    x_train.append(x)\n",
        "    y_train.append(label)\n",
        "\n",
        "x_test, y_test = [], []\n",
        "\n",
        "for image_path, label in zip(val_images, val_labels):\n",
        "    img = image.load_img(image_path, target_size=(32, 32))\n",
        "    if len(img.getbands()) != 3:\n",
        "        print(\"주의: 유효하지 않는 영상 발생\", image_path)\n",
        "        continue\n",
        "    x = image.img_to_array(img)\n",
        "    x = preprocess_input(x)\n",
        "    x_test.append(x)\n",
        "    y_test.append(label)\n",
        "\n",
        "x_train = np.asarray(x_train)\n",
        "y_train = np.asarray(y_train)\n",
        "x_test = np.asarray(x_test)\n",
        "y_test = np.asarray(y_test)\n",
        "y_train = tf.keras.utils.to_categorical(y_train, no_class)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, no_class)\n",
        "\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))  # ResNet에서 특징 추출 부분 설정\n",
        "cnn = Sequential()\n",
        "cnn.add(base_model)\n",
        "cnn.add(Flatten())\n",
        "cnn.add(Dense(1024, activation='relu'))  # 뒷부분을 새로 부착\n",
        "cnn.add(Dense(no_class, activation='softmax'))\n",
        "\n",
        "cnn.compile(loss='categorical_crossentropy', optimizer=Adam(0.0001), metrics=['accuracy'])  # 미세 조정 방식의 학습(낮은 학습률 설정)\n",
        "hits = cnn.fit(x_train, y_train, batch_size=16, epochs=10, validation_data=(x_test, y_test), verbose=1)\n",
        "\n",
        "res = cnn.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"정확도는 \", res[1]*100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Cqb9daPygma",
        "outputId": "1f583ecc-37ff-4599-f14b-3380f28e0beb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "529/529 [==============================] - 813s 1s/step - loss: 1.1113 - accuracy: 0.6355 - val_loss: 1.5429 - val_accuracy: 0.3872\n",
            "Epoch 2/10\n",
            "529/529 [==============================] - 780s 1s/step - loss: 1.0123 - accuracy: 0.6267 - val_loss: 1.6620 - val_accuracy: 0.5896\n",
            "Epoch 3/10\n",
            "529/529 [==============================] - 789s 1s/step - loss: 0.9020 - accuracy: 0.6650 - val_loss: 9.1608 - val_accuracy: 0.6431\n",
            "Epoch 4/10\n",
            "529/529 [==============================] - 787s 1s/step - loss: 0.8696 - accuracy: 0.6861 - val_loss: 1.2669 - val_accuracy: 0.6812\n",
            "Epoch 5/10\n",
            "529/529 [==============================] - 788s 1s/step - loss: 1.0654 - accuracy: 0.5878 - val_loss: 1.4197 - val_accuracy: 0.4407\n",
            "Epoch 6/10\n",
            " 68/529 [==>...........................] - ETA: 11:08 - loss: 1.0384 - accuracy: 0.5809"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Load train.xlsx and val.xlsx\n",
        "train_df = pd.read_excel('/content/train2.xlsx')\n",
        "val_df = pd.read_excel('/content/val2.xlsx')\n",
        "\n",
        "# 경로 수정\n",
        "train_df['names'] = train_df['names'].str.replace('\\', '/')\n",
        "\n",
        "train_images = train_df['names'].tolist()\n",
        "train_labels = train_df['labels'].tolist()\n",
        "\n",
        "val_images = val_df['names'].tolist()\n",
        "val_labels = val_df['labels'].tolist()\n",
        "\n",
        "class_reduce = 0.1  # 부류 수 줄여서 데이터양 줄임(속도와 메모리 효율을 위해)\n",
        "no_class = len(train_df['labels'].unique())  # 부류 개수\n",
        "x_train, y_train = [], []\n",
        "\n",
        "for image_path, label in zip(train_images, train_labels):\n",
        "    img = image.load_img(image_path, target_size=(32, 32))\n",
        "    if len(img.getbands()) != 3:\n",
        "        print(\"주의: 유효하지 않은 이미지 발생\", image_path)\n",
        "        continue\n",
        "    x = image.img_to_array(img)\n",
        "    x = preprocess_input(x)\n",
        "    x_train.append(x)\n",
        "    y_train.append(label)\n",
        "\n",
        "x_test, y_test = [], []\n",
        "\n",
        "for image_path, label in zip(val_images, val_labels):\n",
        "    img = image.load_img(image_path, target_size=(32, 32))\n",
        "    if len(img.getbands()) != 3:\n",
        "        print(\"주의: 유효하지 않는 이미지 발생\", image_path)\n",
        "        continue\n",
        "    x = image.img_to_array(img)\n",
        "    x = preprocess_input(x)\n",
        "    x_test.append(x)\n",
        "    y_test.append(label)\n",
        "\n",
        "x_train = np.asarray(x_train)\n",
        "y_train = np.asarray(y_train)\n",
        "x_test = np.asarray(x_test)\n",
        "y_test = np.asarray(y_test)\n",
        "y_train = tf.keras.utils.to_categorical(y_train, no_class)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, no_class)\n",
        "\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))  # ResNet에서 특징 추출 부분 설정\n",
        "cnn = Sequential()\n",
        "cnn.add(base_model)\n",
        "cnn.add(Flatten())\n",
        "cnn.add(Dense(1024, activation='relu'))  # 뒷부분을 새로 부착\n",
        "cnn.add(Dense(no_class, activation='softmax'))\n",
        "\n",
        "cnn.compile(loss='categorical_crossentropy', optimizer=Adam(0.0001), metrics=['accuracy'])  # 미세 조정 방식의 학습(낮은 학습률 설정)\n",
        "hits = cnn.fit(x_train, y_train, batch_size=16, epochs=10, validation_data=(x_test, y_test), verbose=1)\n",
        "\n",
        "res = cnn.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"정확도는 \", res[1]*100)\n",
        "\n",
        "# 모델 저장\n",
        "cnn.save(\"/content/saved_model.h5\")\n",
        "\n",
        "# 저장된 모델 불러오기\n",
        "loaded_model = load_model(\"/content/saved_model.h5\")\n",
        "\n",
        "# 저장된 모델로 테스트 진행\n",
        "test_results = loaded_model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"불러온 모델의 정확도는 \", test_results[1]*100)\n"
      ],
      "metadata": {
        "id": "4-QVcIl08On2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LxTNxBWk3wCz"
      }
    }
  ]
}